
Outline
* Introduction to Computer Security and Privacy (1.5 hours)
    The meaning of computer security; comparing security with privacy; types of threats and attacks; methods of defense
* Program Security (6 hours)
    Secure programs; nonmalicious program errors; malicious code; controls against program threats
* Operating System Security (6 hours)
    Methods of protection; access control; user authentication
* Network Security (4.5 hours)
    Network threats; firewalls, intrusion detection systems
* Internet Application Security and Privacy (9 hours)
    Basics of cryptography; security and privacy for Internet applications (email, instant messaging, web browsing); privacy-enhancing technologies
* Database Security and Privacy (4.5 hours)
    Security and privacy requirements; reliability, integrity, and privacy; inference; data mining; k-anonymity
* Non-technical Aspects (4.5 hours)
    Administration of security systems; policies; physical security; economics of security; legal and ethical issues

It is expected that you will have read the appropriate sections of the textbook (as noted in the Modules section of LEARN) before class. Additional readings may be assigned as well, and will appear on the lecture slides page; those readings marked as mandatory contain required material for the course; those marked before class must be read before the date of the corresponding lecture.

# Module 1

What is security? 
A computer system is said to be secured if it has the three properties: 

* Confidentiality: access limited to authorized parties
* Integrity: The "right" data is received
* Availability: System or data is there when you want it

You can rely on a secured system to: 
* keep personal data confidential
* allow only authorized access or modifications to resources
* ensure that any produced results are correct
* give you correct and meaningful results whenever you want it

What is privacy? One useful definition is "informational self-determination": 
* you get to **control** information about you: 
    * who gets to see it
    * who gets to use it
    * what they can use it for
    * who they can give it to, etc...

Assets: Things we want to protect, such as hardware, software, data

Vulnerabilities: Weaknesses in a system that may be able to be *exploited* in order to cause loss or harm
* eg. a file server that doesn't authenticate its users

Threats: loss or harm that might befall a system; 4 types:
1. Interception: some unauthorized party has gained access to asset; data file copied, wiretapping to obtain data from network
2. Interruption: asset becomes lost, unavailable, or unusable; eg. malicious destruction of device
3. Modification: modifed asset; eg. change value in database, alter program
4. Fabrication: insert transactions to network; add records to databases

When designing a system, we need to state the threat model: 
* sets of threats we are undertaking to defend against
* whom do we want to prevent from doing what?

Attack: an action that exploits a vulnerability to execute a threat

Control/Defence: Removing or reducing a vulnerability
* goal: control vulnerability to prevent an attack or defend against a threat

Methods of defence: 
* Prevent it
* Deter it: make attack harder or more expensive
* Deflect it: make yourself less attractive to attackers
* Detect it: notice when attack is/has occurred
* Recover from it: mitigate effects of attack

We want to do many things to defend against the same threat - "Defence in depth"

How secure should we make it? 
* Principle of easiest penetration: a system is only as strong as its weakest link
* Principle of Adequate Protection: Security is economics

**Ways to prevent assets**

Cryptography
* data unreadable to an attacker
* digital signatures, cryptographic protocols
* ensure integrity of stored data 

Software controls
* password or other form of access controls
* OS separate users' actions from each other
* virus scanners
* development controls to ensure quality measures on original source code
* personal firewalls

Hardware controls
* Fingerprint readers, smart tokens, firewalls, intrusion detection systems

Physical controls
* Locks, guards, off-site backups

Policies and procedures
* non-technical means used to protect against certain classes of attack
* eg. prevent employee from connecting their own wifi access point to internal company network
* rules about choosing passwords
* training in security practices

# Module 2

## Flaws, faults and failures

Flaw: problem with a program

Security flaw: problem that affects security in some way (confidentiality, integrity, availability)
* faults: potential problem; error in code,data, specification, process, etc.
    * programmer / specifier / inside view
* failure: deviation from desired behaviour
    * user / outside view

To discover and fix faults: 
* When user experiences a failure, we can work backwards to uncover the underlying fault. 
* Intentionally try to cause failures
* Faults are fixed by making small edits to the program- "penetrate and patch"

Problems with patching: 
* pressure to patch a fault is often high, causing programmer to focus on observed failure rather than looking at what may be a more serious underlying problem
* fault may have caused other, unnoticed faults; partial fix cause inconsistencies or other problems
* patch may introduce new faults

Unexpected behaviours: 
* when program's behaviour is specificed, spec lists the things the program must do
* most implementors wouldn't care if it did additional things as well
* from security / privacy point of view, extra behaviours can be bad
* when implementing security or privacy relevant program, add "and nothing else" to the spec

Types of security flaws
* Intentional / inherent
    * malicious: intentionally asserted to attack systems
        * targeted: to attack a particular system
        * nontargeted
    * nonmalicious: features that can cause failure when used by attacker
* unintentional

## Unintentional security flaws

TLS Heartbeat mechanism: designed to keep SSL/TLS connections alive even when no data is being transmitted. Heartbeat messages sent by one peer containing random data and a payload length, the other peer is supposed to respond with mirror of exactly the same data. 

Heartbleed Bug in OpenSSL (2014)
* Missing bound check in the code
* attacker request that a TLS server hand over relatively large slice of its private memory space
* memory space stores server's private key material and TLS session keys

Apple's SSL/TLS Bug (2014)
* bug occurs in code used to check validity of server's signature on a key used in SSL/TLS connection
* active attacker could exploit this flaw to get a user to accept a counterfeit key chosen by the attacker

```C
static OSStatus
SSLVerifySignedServerKeyExchange(SSLContext *ctx, bool isRsa, SSLBuffer signedParams, uint8_t *signature, UInt16 signatureLen)
{
    OSStatus        err;
    ...

    if ((err = SSLHashSHA1.update(&hashCtx, &serverRandom)) != 0)
        goto fail;
    if ((err = SSLHashSHA1.update(&hashCtx, &signedParams)) != 0)
        goto fail;
        goto fail;
    if ((err = SSLHashSHA1.final(&hashCtx, &hashOut)) != 0)
        goto fail;
    ...

fail:
    SSLFreeBuffer(&signedHashes);
    SSLFreeBuffer(&hashCtx);
    return err;
}
```

Second `goto fail` statement always execute if the first two checks are successful. The third check is bypassed and 0 is returned as the value of error. 

Types of unintentional flaws: 
* buffer overflows
* integer overflows
* format string vulnerabilities
* incomplete mediation
* TOCTTOU erros

### Buffer overflows

```c
#define LINELEN 1024
char buffer[LINELEN];
gets(buffer);
    //or
strcpy (buffer, argv[1]);
```

The `gets` and `strcpy` functions do not check that the string will fit in the buffer. 

If the attacker can write data past the end of an array on the stack, she can overwrite things like the saved return address - when the function returns, program will jump to any address of her choosing. 

Targets programs on local machine that run with setuid (superuser) privileges, or network daemons on a remote machine

Variants: 
* attacks which work when a single byte can be written past the end of the buffer (caused by off-by-one error)
* overflows of buffers on heap instead of stack
* jump to other parts of program, or parts of standard libraries, instead of shellcode

Defence: 
* Programmer: use language with bounds checking and catch the exceptions
* Compiler: place padding between data andreturn addresses (canaries)
    * detect if stack has been overriden before return from each function
* Memory: non-excutable stack
    * memory page is either writable or executable, but never both
* OS: Stack (and sometimes code, heap, libraries) at random virtual addresses for each process

### Integer overflows
* Program assumes integer is always positive, overflow will make signed integer wrap and become negative, violated assumption
    * casting of large unsigned integer to signed integer
    * result of mathematical operation
* attacker passvalues to program that triggers overflow

### Format string vulnerabilities

* Unfiltered user input is used as format string in `printf()`, `fprintf()`, `sprintf()`
* `printf(buffer)`instead of `printf("%s", buffer)`
    * parse buffer for %'s and usewhatever is currently on th estack to process found format parameters
* `printf("%s%s%s%s")` likely crashes program
* `printf("%x%x%x%x")` dumps part of the stack
* `%n` write to address found on stack

```c
char output[44];
char buffer[44];
snprintf(buffer, sizeof(buffer), "Input %s", input);
sprintf(output, buffer);
```
* what happens When input=%48d+(address of a libc routine)? 

### Incomplete mediation
* inputs to programs often specified by unstrusted users
* users sometimes mistype data in webform
* mediation ensures what user has entered constitues a meaningful request
* incomplete mediation: application accepts data from the user
* focus on catching entries clearly wrong: 
    * not well formed
        * DOB: 1980-04-31
    * unreasonable values: 
        * DOB: 1876-10-12
    * inconsistent with other entries
* make sure any user-specified input falls within well-specified values, known to be safe
* concerns examples: 
    * SQL injection - student name is '); DROP TABLE Students;--
    * data causing buffer overflow

Client-side mediation: Javascript code will first run validation checks on the data entered; if you enter invalid data, popup will prevent you from submitting it

Many web sites rely on client to keep state for them. They put hiddenfields in the form which are passed back to the server when the user submits the form. 

Client-side mediation is an OK method to use in order to have a friendlier user interfae, but is useless for security purposes

If user: 
* turns off Javascript
* Edits form before submitting it (Greasemonkey)
* Writes a script that interacts with the web server instead of using a web browser
* Connects to server manually (telnet server.com 80)

Now the user can send arbitrary, unmediated values to the server. The user can also modify client-side state. 

Example: 

1. At bookstore website, user orders a book. Server replies with a form asking the address to ship to, the form has hidden field storing the user's order

    ```html
    <input type="hidden" name="isbn" value="0-13-239077-9"> 
    <input type="hidden" name="quantity" value="1">
    <input type="hidden" name="unitprice" value="111.00">
    ```

    User can change unitprice to "50.00" before submitting the form

2. Change quantity to "-1" to be paid. 


Defences against incomplete mediation: 
* Server-side mediation
* For user input: 
    * Careful check on all values on all field
    * values can contain completely arbitrary 8-bit data and be of any length
* For state stored by client: 
    * make sure client has not modified data in any way

### TOCTTOU errors

TOCTTOU (Tock-too) errors: Time-of Check to Time-of Use; also known as race condition errors

Occur when
1. user requests system to perform an action
2. system verifies the user is allowed to perform the action
3. system performs the action

The state of the system changes between step 2 and 3. 

Example: Setuid

* runs with superuser privileges so it can allocate terminals to users (a privileged operation)
* Supports a command to write contents of terminal to log file
    1. Checks if user has permission to write to requested file
    2. Open file for writing
* Attacker makes a symbolic link:   
    `logfile -> file_she_owns`
* between "check" and "open", she changes it   
    `logfle->/etc/passwd`

Defence: When performing a privleged action on behalf of another party, make sure all information relevant to access control decision is constant between time of check and time of action: 
* keep a private copy of request itself so that request can't be altered during the race
* whenever possible, act on object itself, not some level of indirection
    * eg. make decisions based on file handles, not file names
* if not possible, use locks to ensure object is not changed during race

## Malicious code: Malware

Malware is written with malicious intent. They need to be executed in order to cause harm. 

Malware can get executed by: 
1. User action
    * downloading and running malicious software
    * viewing web page with malicious code
    * opening executable email attachment
    * inserting CD/DVD or USB flash drive
2. Exploiting existing flaw in a system
    * buffer overflows in network daemons
    * buffer overflows in email clients or web browsers

Type of malware
1. Virus: 
    * add itself to benign programs/files
    * code for spreading + code for attack
    * usually activated by user
2. Worms
    * malicious code spreading with no or little user involvement
3. Trojans
    * malicious codehidden in seemingly innocent program that you download
4. Logic bombs:
    * malicious code hidden in programs already on your machine

### Virus

Virus infects other files
    * executable programs
    * data documents with executable code (macros)

When file is executed (or sometimes just opened), virus activates, and tries to infect other files with copies of itself to spread

Infection: 
* modify existing program or document (host) such that executing or opening it will transfer control to virus
    * for executable programs, virus modify other programs and copy itself to beginning of targets' program code
    * for document with macros, virus edit other documents to add itself as a macro which start automatically when file is opened
* often try to infect computer itself to automatically activate when computer is booted
    * put in boot sector of hard disk
    * add to list of startup programs
    * infect one of more programs OS runs at boot time

Spreading: 
* by users sending infected files to others, or putting them in p2p network
* usually require user action (otherwise it's usually a worm)

Virus try to evade detection by disabling active virus scanning software

Virus carries payload, which will activate at some point to: 
* erase hard drive
* sbutly corrupt some spreadsheets
* install keystroke logger to capture online banking password
* start attacking a particular target website

Look for virus when: 
* files added to computer
* scan entire state of computer from time to time

Look for virus using
1. signature-based protection
    * keeps a list of known viruses. For each virus, store the signature - characteristic features
        * features of virus code - infection code or payload code
        * patterns of virus - where on system it hides, how it propagates from one place to another

    To evade signature based virus scanners, some viruses are polymorphic - it makes a modified copy each time
    * most of virus code encrypted
    * virus starts with decryption routine
    * when virus spreads, it encrypts the new copy wiht a newly chosen random key

2. behaviour-based protection
    * look for suspicious patterns of behaviour; sometimes run them in sandbox first

False negatives vs. false positives?
* base rate= rate of virus in all programs
* many more false positives than true positives, potentially causing true positives to be overlooked or scanner disabled. 

### Worms

Worm is a self-contained piece of code that can replicate with little or no user involvement. Typically: 
1. Exploits security flaw in widely deployed software on computer
2. Search for other computers on local network or internet to infect
3. May have payload that activates at certain time, or by another trigger

Morris worm (1988): Once infected, a machine try to infect other machines by: 
* exploit a buffer overflow in "finger" daemon
* use a backdoor left in the "sendmail" daemon
* try a dictionary attack against local users' passwords. Success => login, spread to other machines they can access without requiring a password

Code Red worm (2001): Exploit buffer overflow in Microsoft's ISS web server. Infected machine would: 
* deface its home page
* launch attacks on other web servers
* launch a denial-of-service attack on some websites, including www.whitehouse.gov
* install backdoor to deter disinfection

Slammer worm (2003): performed denial-of-service attack
* first example of "Warhol worm" - can infect nearly all vulnerable machines in 15 minutes
* exploited buffer overflow in Microsoft's SQL server
* vulnerable machine infected with a single UDP packet
    * enables worm to spread extremely quickly
    * exponential growth

Stuxnet (2010)
* Allegedly created by US and Israeli intelligence agencies
* Allegedly targeted Iranian uranium enrichment program
* Targets Siemens SCADA systems installed on Windows; application: operation of centrifuges
* uses many criteria to select which systems to attack after infection
* promiscuous: used 4 different zero-day attacks to spread; installed manually for air-gapped systems
* stealthy: intercepts commands to SCADA system and hides its presence
* targeted: detects if variable-frequency drives are installed, operating between 807-1210 Hz, then subtly changes the frequencies so that distortion and vibrations occur resulting in broken centrifuges

WannaCry (2017)
* ransomware - demand ransom to return hostage resource to victim, can also be scareware
* exploits a Windows SMB vulnerability originally discovered by NSA, who kept it secret
* vulnerability leaked by "Shadow Brokers" in April 2017
* Microsoft released a patch, but many systems remained unpatched

CryptoLocker (2013)
* spread with spoofed email attachment from a botnet
* encrypted victim's hard drive
* demanded ransom for private key

### Trojan Horses
* programs which claim to do something innucuous, and also hide malicious behaviours
* get user to run code of attacker's choice, by providing some code user wants to run
    * PUP (potentially unwanted programs)
    * scareware: user may pay attacker to run the code
* payload can be anything
* Trojan horses do not spread themselves between computers, but rely on users to execute or share the software

### Logic Bombs
* malicious code hiding in software already on computer, waiting for a trigger to execute its payload
* written by insiders, meant to be triggered in the future (eg. when insider leaves company)
* payload is usually dire
    * erase data, corrupt data, encrypt data and ask for money
* trigger is usually something the insider can affect once he is no longer an insider
    * when a particular account gets 3 deposits of equal value in one day
    * when a special sequence of numbers is entered on the keypad of an ATM
    * time bomb

Trojan horses and logic bombs are hard to spot because user is intentionally running the code. Countered by preventing the payload from doing bad things. 

## Other Malicious code

* web bugs (beacon)
* back doors
* salami attacks
* privilege escalation
* rootkits
* keystroke logging
* interface illusions


### Web Bugs

* object (usually on 1x1 pixel transparent image) embedded in a web page, which is fetched from a different server than the one that served the web page itself. 
* Information is sent without your knowledge to third parties (often advertisers): 
    * IP address
    * contents of cookies
    * personal info the site has about you
* issue of privacy: instructs browser to behave in a way contrary to principle of informational self-determination

```html
<IMG WIDTH="1" HEIGHT="1" 
src="http://app.insightgrit.com/1/nat?
id=79152388778&ref=http://www.eff.org/
Privacy/Marketing/web bug.html&z=668951
&purl=http://quicken.intuit.com/">
```

* With help of cookies, advertiser can learn what websites a person is interested in. 
* Advertiser can learn person's identity if he can place ads on social networking site
* HTTP request for Facebook ad:   
    GET [pathname of ad]  
    Host: ad.doubleclick.net  
    Referer: http://www.facebook.com/    
    profile.php?id=123456789&ref=name   
    Cookie: id=2015bdfb9ec...   

### Back doors

Also called trapdoor, is a set of instructions designed to bypass normal authentication mechanism and allow access to system to anyone who knows the back door exists. 

Real examples: 
* debugging back door left in sendmail
* bacdoor planted by Code Red worm
* port knocking: system listens for connection attempts to a certain pattern of (closed) ports. All connection attempts will fail, but with right pattern, system will open, for example, a port with root shell attached to it
* attempted hack to Linux kernel source code: 
    ```c
    if ((options == (__WCLONE|__WALL)) && (current->uid=0))
        retval = -EINVAL;
    ```

Sources of back doors
* forget to remove them
* intentionally left for 
    * testing purpose
    * maintenance purposes
    * legal reasons
    * malicious purposes

### Salami attacks
* attack made up of many smaller, often considered inconsequential, attacks
* example: 
    * send fractions of cents of round-off error from many accounts to a single account owned by the attacker
    * credit card thieves make very small charges to many cards
    * clerks slightly overcharge customers for merchandise
    * gas pumps misreport amount of gas dispensed

### Privilege escalation 

An attack that raises privilege level of attacker. Source: 
* part of system that legitimately runs with higher privilege tricked into executing commands (with higher privilege) on behalf of the attacker
* attacker trick system into thinking he is a legitimate higher-privileged user
    * problems with authentication system
    * obtain session id/cookie from another use to access their bank account

Vertical privilege escalation: user or process can access a higher level of access than an adimitrator or system developer intended; eg. performing kernel-level operation

Horizontal privilege escalation: application allows attacker to gain resources usually protected from an application or user; eg. by impersonating another user

### Rootkits

Tool used by script kiddies. 

Has two main parts: 
* method for gaining unauthorized root / admin privileges on a machine
    * exploit some known flaw in the system
    * leaves behind a back door so attacker can get back in later
* a way to hide its existence
    * clean up log message that might have been created by the exploit
    * modify commands like `ls` or `ps` so they don't report files or processes belonging to the rootkit
    * modify kernel so no user program will learn about these files or processes

Example: Sony XCP
* Sony audio CDs equipped with XCP - extended copy protection
* when inserting CD, it contains an `autorun.exe` file that automatically executes to install the rootkit
* rootkit modify the CD driver in Windows so that nay process that tried to read the contents of an XCP-protected CD into memory would get garbled output
* rooknit was hard to find and uninstall
* Sony released an uninstaller after complaints and law suits, but the uninstaller left a back door

### Keystroke Logging

Attacker may install keyboard logger on computer to keep record of 
* emails / IM sent
* password typed

The data can then be accessed locally or sent to a remote machine over the Internet. 

Installed by: 
* malware
* family member to spy on children, spouses, etc.

Types: 
* Application-specific Loggers: record keystrokes associated with a particular application
* System keyboard loggers: record all keystrokes that are pressed (maybe only for a particular target user)
* Hardware keyboard loggers: sits between keyboard and computer; 
    * works with any OS and undetectable in software

### Interface Illusions

User interface gives unwanted (nonstandard) side effects. 

Example: dragging scrollbar dragged a program from a malicious website into your Startup folder, in addition to scrolling the document

Phishing: Make a fake website look like the real thing. 

Phishing detection: 
* unusual email / URL
* attachments with uncommon names
* typos, unusual wordings
* no https


Keyboard logging, interface illusions, and phishings are all examples of **Man-in-the-middle attacks**
* The webiste/program/system you're communicating isn't the one you think you are communicating with
* intercepts communication from user, then passes it onto the intended other party
    * user thinks nothing is wrong, because expected behaviours are observed
* man-in-the-middle can hijack session to insert malicious command, once , for example, you've authenticated to your bank
* can edit results (eg. bank balances) so there's no visible record

## Nonmalicious flaws

Covert channels
* creates capability to transfer sensitive / unauthorized information through channel that is not supposed to transmit that info
    * what info can be transmitted may be determined by policy, guidelines, physical limitations, etc.
* eg. by using binary bit stream

Side channels
* attack based on information gained from implementation of a computer system
* carefully watches how the system behaves
* usually has to be somewhere in the physical vicinity
* potential attack vectors: 
    * bandwith consumption
    * shoulder-surfing
    * reflection of screen
    * timing computations
    * power consumption
    * electromagnetic emission
    * sound emission
    * cache access
    * differential power analysis
    * differential fault analysis

## Controls against security flaws in programs

Software goes through several stages in its lifecycle:
- Specication
- Design
- Implementation
- Change management
- Code review
- Testing
- Documentation
- Maintenance

Design programs to have less security flaws
- modularity
    - each module responsible for single subtask, easier to check for flaws, test, maintain, reuse, etc.
    - low coupling (interactions between modules)
- encapsulation
    - modules mostly self-contained, sharing information only as necessary
    - reduces coupling
    - developer of one module does not need to know how a different module is implemented - she should only know about published interfaces (API)
- information hiding
    - internals of one module not visible to other modules
    - implementation and internal state not modifiable except for API
- mutual suspicion
    - modules check that their inputs are sensible before acting on them
    - defend against flaws or malicious behaviour on the part of other modules
        - corrupt data in one module should be prevented from corrupting other modules
- confinement
    - if module A needs to call potentially untrustworthy Module B, sandbox it
        - run in a limited environment that only has access to resources it absolutely needs
    
Implementation phase: 
* Don't use C if possible
* static code analysis
    * software products that help you find security flaws- buffer overflow, TOCTTOU, etc.
* formal methods
    * prove code does exactly what it's supposed to do
    * impossible to do in general
* genetic diversity
    * worms and viruses can spread because many machines run the same vulnerable code
    * more variety -> smaller likelihood of common flaw

Source control and configuration control
- track all changes to either source code of configuration information in somemanagement system
- in attempted backdoor in Linux source, Bitkeeper notice change to source repo that didn't match any valid checkin

Code review
- have people look at code to try to find flaws
- guided code reviews: author explains code to reviewer
    - why each change was made
    - what effects it might have on other parts of the system
    - what testing needs to be done
- author inserts intentional flaws into code - reviewers will look harder

Testing phase: 
- try to make programers do unspecified things
- black box testing
    - fuzz testing: supply completely random data to the object, as
        - input in API
        - data file
        - data received from network
        - UI events
- white/clear box testing
    - regression testing

Documentation
- document choices that worked and didn't work
- make checklist of things to be careful of

Standards, process, and audits
- standards: rules about how things are done at each stage of software lifecycle; incorporate controls
    - what design methodologies?
    - what kind of implementation diversity?
    - what change management system?
    - what kind of code review?
    - what kind of testing?
- formal processes specify how each standard should be implemented
- audits: external personnel comes in and verifies that processes are followed properly
