

## Problem-solving using Search

* Find a goal state, given constraints on the goal
    * any goal state: eg. n-queens, crossward puzzles
    * optimal goal state: travelling saleman problem, set covering problem
* find a sequence actions that lead to goal state
    * sliding puzzle, river crossing puzzle
    * optimal sequence - sliding puzzle with least number of moves

Methodology: formulate problem solving as search on a graph
1. Nodes: specify representation of states, specify initial and goal states
2. Arcs: specify actions (successor function, neighbourhood function) that takes us from one state to another
3. Find a path from initial to goal state

Depending on the problem, assign a cost to arcs or nodes

Graph search algorithm

```
L = [start nodes]
while L != empty do
    select and remove a node from L, call it p
    if p is a goal node, return (success)
    generate all successor states of p, and add them to L
return (fail)
```

FIFO queue gives BFS
LIFO queue gives DFS
Priority queue gives informed search (greedy, A*)

What to do about repeated states? 
0. Nothing
1. Don't return to a state that you just came from
2. Do not create paths with cycles in them (look at ancestors of a node)
3. Do not generate any state that was ever generated before (keep closed list using hash table)

### Informed (heuristic) search
- assign cost to each action/rule/arc
- heuristic function: 
    h(n) = estimated cost of cheapest path from state at node n to a goal state

For example, in a 8-puzzle (sliding) with initial node

---|---|---
---|---|---
5 | 4 |
6 | 1 | 8
7 | 3 | 2

we can have heuristic function: 
1. h(n) = number of tiles out of place in node n. Then, h(node_initial) = 7, and h(node_goal) = 0
2. h(n) = sum of Manhatten distance of tiles out of place
    - h(n_I) = 18
    - h(n_G) = 0

And greedy search algorithm: 
```
L = [start nodes]
while L != empty do
    remove node with lowest h(n) value from L, call it p
    if p is a goal node, return (success)
    generate all successor states of p, and add them to L
endwhile
return (fail)
```

* Not guaranteed to find optimal path
* May not terminate

### A* search

Minimize total path cost. 

Let f*(n) = g*(n) + h*(n) be the costof anoptimal path going through node n, where
* g*(n) is cost of optimal path from initial node to n
* h*(n) is cost of an optimal path from n to goal node

But f*(n) is difficult to know, so we estimate. 

Let f(n) = g(n) + h(n) be the cost of a path going throug node n to goal node, where
* g(n) is cost of path from initial state to n that was found
* h(n) is a heuristic estimate of cost from n to a goal

Algorithm A* for searching a tree: 

```
L = [start nodes]
while L != empty do
    remove node with lowest f(n) value from L, call it p
    if p is a goal node, return (success)
    generate all successor states of p, and add them to L
endwhile
return (fail)
```

**Admissible heuristics**

Definition: A heuristic function h(n) is admissible if h(n) <= h*(n) for all n. 

Theorem: If h(n) is admissible, the A* algorithm is guaranteed to find an optimal path to a goal node. 

**Consistent (monotone) heuristics**

Definition: A heuristic function h(n) is consistent if h(n) <= cost(n, n') + h(n') for all n, n' a successor of n

Theorem: If h(n) is consistent, the A* algorithm is guaranteed to find an optimal path to a goal node. 

**Dominating heuristics**

Definition: Given admissible heuristics h1(n) and h2(n), h2(n) dominates h1(n) if, for all nodes n,   
        h2(n) >= h1(n),  
    and there exists a node n' such that  
        h2(n') > h1(n')

Theorem: A* with h1(n) expands at least as many nodes as A* with h2(n), if h2(n) dominates h1(n)

Complexity results for A*
* Good news: 
    * A* is complete, optimal, and optimally efficient
    * no algorithm with the same information can do better
* Bad news: 
    * assume a single goal, search a tree,and each action is reversible
    * time complexity of A* is exponential